{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad83d4f2-ea0e-42bb-a781-74aae1f1ee16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "\n",
    "from qiskit import QuantumCircuit, transpile\n",
    "from qiskit_aer import AerSimulator\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import (roc_auc_score, accuracy_score, precision_score, \n",
    "                             recall_score, f1_score, confusion_matrix, \n",
    "                             roc_curve, classification_report)\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b319fed-f145-4248-8bbe-06c1f2f43ce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Directory structure created\n"
     ]
    }
   ],
   "source": [
    "os.makedirs('output', exist_ok=True)\n",
    "os.makedirs('output/data', exist_ok=True)\n",
    "os.makedirs('output/models', exist_ok=True)\n",
    "os.makedirs('output/plots', exist_ok=True)\n",
    "print(\" Directory structure created\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5087e9c-30b5-4326-a30b-dd966674f718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "STEP 1: DATA LOADING & EXPLORATION\n",
      "============================================================\n",
      "\n",
      "Raw Dataset Shape: (768, 9)\n",
      "Columns: ['pregnancies', 'glucose', 'bloodpressure', 'skinthickness', 'insulin', 'bmi', 'diabetespedigreefunction', 'age', 'outcome']\n",
      "\n",
      "Class Distribution (Outcome):\n",
      "outcome\n",
      "0    500\n",
      "1    268\n",
      "Name: count, dtype: int64\n",
      "Diabetes Percentage: 34.90%\n",
      "\n",
      "Missing Values:\n",
      "pregnancies                 0\n",
      "glucose                     0\n",
      "bloodpressure               0\n",
      "skinthickness               0\n",
      "insulin                     0\n",
      "bmi                         0\n",
      "diabetespedigreefunction    0\n",
      "age                         0\n",
      "outcome                     0\n",
      "dtype: int64\n",
      "\n",
      "✅ Data exploration complete\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 1: DATA LOADING & EXPLORATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "df_raw = pd.read_csv('diabetes.csv')   \n",
    "df_raw.columns = df_raw.columns.str.strip().str.lower()\n",
    "\n",
    "print(f\"\\nRaw Dataset Shape: {df_raw.shape}\")\n",
    "print(f\"Columns: {list(df_raw.columns)}\")\n",
    "\n",
    "print(f\"\\nClass Distribution (Outcome):\")\n",
    "print(df_raw['outcome'].value_counts())\n",
    "\n",
    "print(f\"Diabetes Percentage: {df_raw['outcome'].mean() * 100:.2f}%\")\n",
    "\n",
    "print(f\"\\nMissing Values:\\n{df_raw.isnull().sum()}\")\n",
    "\n",
    "data_info = {\n",
    "    'raw_shape': df_raw.shape,\n",
    "    'columns': list(df_raw.columns),\n",
    "    'diabetes_percentage': float(df_raw['outcome'].mean() * 100),\n",
    "    'missing_values': df_raw.isnull().sum().to_dict(),\n",
    "    'class_distribution': df_raw['outcome'].value_counts().to_dict()\n",
    "}\n",
    "\n",
    "with open('output/data/data_info.json', 'w') as f:\n",
    "    json.dump(data_info, f, indent=2)\n",
    "\n",
    "print(\"\\n Data exploration complete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ca18560-61d3-47f8-a7e5-b2691be298d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "STEP 2: FEATURE ENGINEERING & SELECTION\n",
      "============================================================\n",
      "\n",
      "Removing outliers...\n",
      "Removed 319 outliers (41.5%)\n",
      "\n",
      "Top Features by Correlation:\n",
      "glucose          0.469962\n",
      "bmi              0.332163\n",
      "pregnancies      0.209009\n",
      "skinthickness    0.172630\n",
      "age              0.164649\n",
      "dtype: float64\n",
      "\n",
      "Performing feature selection...\n",
      "Selected Features: ['glucose', 'bmi', 'diabetespedigreefunction', 'age']\n",
      "\n",
      "✅ Feature engineering complete\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 2: FEATURE ENGINEERING & SELECTION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "X = df_raw.drop('outcome', axis=1)\n",
    "y = df_raw['outcome']\n",
    "\n",
    "zero_as_missing = ['glucose', 'bloodpressure', 'skinthickness', 'insulin', 'bmi']\n",
    "X[zero_as_missing] = X[zero_as_missing].replace(0, np.nan)\n",
    "\n",
    "X = X.fillna(X.median())\n",
    "\n",
    "print(\"\\nRemoving outliers...\")\n",
    "Q1 = X.quantile(0.25)\n",
    "Q3 = X.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "outlier_mask = ~((X < (Q1 - 3 * IQR)) | (X > (Q3 + 3 * IQR))).any(axis=1)\n",
    "X_clean = X[outlier_mask]\n",
    "y_clean = y[outlier_mask]\n",
    "print(f\"Removed {len(X) - len(X_clean)} outliers ({(1-len(X_clean)/len(X))*100:.1f}%)\")\n",
    "\n",
    "X_clean = X_clean.loc[:, X_clean.nunique() > 1]\n",
    "\n",
    "correlations = X_clean.corrwith(y_clean).abs().sort_values(ascending=False)\n",
    "print(f\"\\nTop Features by Correlation:\")\n",
    "print(correlations.head())\n",
    "\n",
    "print(\"\\nPerforming feature selection...\")\n",
    "selector = SelectKBest(mutual_info_classif, k=4)\n",
    "X_selected = selector.fit_transform(X_clean, y_clean)\n",
    "selected_features = X_clean.columns[selector.get_support()].tolist()\n",
    "print(f\"Selected Features: {selected_features}\")\n",
    "\n",
    "df_processed = pd.DataFrame(X_selected, columns=selected_features)\n",
    "df_processed['Outcome'] = y_clean.values   \n",
    "df_processed.to_csv('output/data/processed_dataset.csv', index=False)\n",
    "\n",
    "feature_info = {\n",
    "    'original_features': list(X.columns),\n",
    "    'selected_features': selected_features,\n",
    "    'selection_method': 'Mutual Information',\n",
    "    'feature_scores': {\n",
    "        feat: float(score)\n",
    "        for feat, score in zip(\n",
    "            selected_features,\n",
    "            selector.scores_[selector.get_support()]\n",
    "        )\n",
    "    }\n",
    "}\n",
    "\n",
    "with open('output/data/feature_selection.json', 'w') as f:\n",
    "    json.dump(feature_info, f, indent=2)\n",
    "\n",
    "print(\"\\n Feature engineering complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd77da02-99c6-476d-aa67-0d7f72a17e92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "STEP 3: DATA PARTITIONING & SCALING\n",
      "============================================================\n",
      "\n",
      "Data Partition Sizes:\n",
      "  Training:     269\n",
      "  Validation:    45\n",
      "  Test:         135\n",
      "\n",
      "Class Distribution (Outcome):\n",
      "  Train: [172  97]\n",
      "  Val:   [29 16]\n",
      "  Test:  [86 49]\n",
      "\n",
      "Performing feature selection on training data...\n",
      "Selected Features: ['glucose', 'bmi', 'diabetespedigreefunction', 'age']\n",
      "\n",
      "Applying SMOTETomek to training data...\n",
      "Balanced Training Size: 308\n",
      "Balanced Distribution: [154 154]\n",
      "\n",
      "✅ Data partitioning & preprocessing complete\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 3: DATA PARTITIONING & SCALING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    X_clean, y_clean, test_size=0.30, random_state=42, stratify=y_clean\n",
    ")\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.143, random_state=42, stratify=y_temp\n",
    ")\n",
    "\n",
    "print(f\"\\nData Partition Sizes:\")\n",
    "print(f\"  Training:   {len(X_train):5d}\")\n",
    "print(f\"  Validation: {len(X_val):5d}\")\n",
    "print(f\"  Test:       {len(X_test):5d}\")\n",
    "\n",
    "print(\"\\nClass Distribution (Outcome):\")\n",
    "print(f\"  Train: {np.bincount(y_train.astype(int))}\")\n",
    "print(f\"  Val:   {np.bincount(y_val.astype(int))}\")\n",
    "print(f\"  Test:  {np.bincount(y_test.astype(int))}\")\n",
    "\n",
    "print(\"\\nPerforming feature selection on training data...\")\n",
    "selector = SelectKBest(mutual_info_classif, k=4)\n",
    "\n",
    "X_train_sel = selector.fit_transform(X_train, y_train)\n",
    "X_val_sel = selector.transform(X_val)\n",
    "X_test_sel = selector.transform(X_test)\n",
    "\n",
    "selected_features = X_train.columns[selector.get_support()].tolist()\n",
    "print(f\"Selected Features: {selected_features}\")\n",
    "\n",
    "print(\"\\nApplying SMOTETomek to training data...\")\n",
    "resampler = SMOTETomek(random_state=42)\n",
    "X_train_balanced, y_train_balanced = resampler.fit_resample(X_train_sel, y_train)\n",
    "\n",
    "print(f\"Balanced Training Size: {len(X_train_balanced)}\")\n",
    "print(f\"Balanced Distribution: {np.bincount(y_train_balanced.astype(int))}\")\n",
    "scaler_classical = RobustScaler()\n",
    "\n",
    "X_train_balanced_scaled = scaler_classical.fit_transform(X_train_balanced)\n",
    "X_val_scaled = scaler_classical.transform(X_val_sel)\n",
    "X_test_scaled = scaler_classical.transform(X_test_sel)\n",
    "\n",
    "scaler_quantum = MinMaxScaler(feature_range=(0, np.pi))\n",
    "\n",
    "X_train_quantum = scaler_quantum.fit_transform(X_train_sel)\n",
    "X_val_quantum = scaler_quantum.transform(X_val_sel)\n",
    "X_test_quantum = scaler_quantum.transform(X_test_sel)\n",
    "\n",
    "with open('output/models/scaler_classical.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler_classical, f)\n",
    "\n",
    "with open('output/models/scaler_quantum.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler_quantum, f)\n",
    "\n",
    "with open('output/models/feature_selector.pkl', 'wb') as f:\n",
    "    pickle.dump(selector, f)\n",
    "\n",
    "print(\"\\n Data partitioning & preprocessing complete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "968def52-dfba-4100-8bd9-46a30286e2c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "STEP 4: TRAINING CLASSICAL MODELS (4 CLASSIFIERS)\n",
      "============================================================\n",
      "\n",
      "→ Training Logistic Regression...\n",
      "  Val AUC: 0.9095 | Test AUC: 0.8308\n",
      "\n",
      "→ Training Random Forest...\n",
      "  Val AUC: 0.8750 | Test AUC: 0.7907\n",
      "\n",
      "→ Training Gradient Boosting...\n",
      "  Val AUC: 0.8578 | Test AUC: 0.7916\n",
      "\n",
      "→ Training Neural Network...\n",
      "  Val AUC: 0.8276 | Test AUC: 0.7425\n",
      "\n",
      "✅ Classical model training complete\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 4: TRAINING CLASSICAL MODELS (4 CLASSIFIERS)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "results = {}\n",
    "predictions = {}\n",
    "models_dict = {}\n",
    "\n",
    "print(\"\\n→ Training Logistic Regression...\")\n",
    "lr = LogisticRegression(\n",
    "    C=0.5,\n",
    "    max_iter=1000,\n",
    "    solver='saga',\n",
    "    class_weight='balanced',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "lr.fit(X_train_balanced_scaled, y_train_balanced)\n",
    "\n",
    "y_val_proba = lr.predict_proba(X_val_scaled)[:, 1]\n",
    "y_test_pred = lr.predict(X_test_scaled)\n",
    "y_test_proba = lr.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "results['Logistic Regression'] = {\n",
    "    'Val_AUC': roc_auc_score(y_val, y_val_proba),\n",
    "    'Test_AUC': roc_auc_score(y_test, y_test_proba),\n",
    "    'Test_Accuracy': accuracy_score(y_test, y_test_pred),\n",
    "    'Test_Precision': precision_score(y_test, y_test_pred),\n",
    "    'Test_Recall': recall_score(y_test, y_test_pred),\n",
    "    'Test_F1': f1_score(y_test, y_test_pred)\n",
    "}\n",
    "\n",
    "predictions['lr'] = y_test_proba\n",
    "models_dict['lr'] = lr\n",
    "\n",
    "print(f\"  Val AUC: {results['Logistic Regression']['Val_AUC']:.4f} | \"\n",
    "      f\"Test AUC: {results['Logistic Regression']['Test_AUC']:.4f}\")\n",
    "\n",
    "print(\"\\n→ Training Random Forest...\")\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=12,\n",
    "    min_samples_split=6,\n",
    "    min_samples_leaf=3,\n",
    "    class_weight='balanced',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf.fit(X_train_balanced_scaled, y_train_balanced)\n",
    "\n",
    "y_val_proba = rf.predict_proba(X_val_scaled)[:, 1]\n",
    "y_test_pred = rf.predict(X_test_scaled)\n",
    "y_test_proba = rf.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "results['Random Forest'] = {\n",
    "    'Val_AUC': roc_auc_score(y_val, y_val_proba),\n",
    "    'Test_AUC': roc_auc_score(y_test, y_test_proba),\n",
    "    'Test_Accuracy': accuracy_score(y_test, y_test_pred),\n",
    "    'Test_Precision': precision_score(y_test, y_test_pred),\n",
    "    'Test_Recall': recall_score(y_test, y_test_pred),\n",
    "    'Test_F1': f1_score(y_test, y_test_pred)\n",
    "}\n",
    "\n",
    "predictions['rf'] = y_test_proba\n",
    "models_dict['rf'] = rf\n",
    "\n",
    "print(f\"  Val AUC: {results['Random Forest']['Val_AUC']:.4f} | \"\n",
    "      f\"Test AUC: {results['Random Forest']['Test_AUC']:.4f}\")\n",
    "\n",
    "print(\"\\n→ Training Gradient Boosting...\")\n",
    "gb = GradientBoostingClassifier(\n",
    "    n_estimators=250,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=3,\n",
    "    subsample=0.8,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "gb.fit(X_train_balanced_scaled, y_train_balanced)\n",
    "\n",
    "y_val_proba = gb.predict_proba(X_val_scaled)[:, 1]\n",
    "y_test_pred = gb.predict(X_test_scaled)\n",
    "y_test_proba = gb.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "results['Gradient Boosting'] = {\n",
    "    'Val_AUC': roc_auc_score(y_val, y_val_proba),\n",
    "    'Test_AUC': roc_auc_score(y_test, y_test_proba),\n",
    "    'Test_Accuracy': accuracy_score(y_test, y_test_pred),\n",
    "    'Test_Precision': precision_score(y_test, y_test_pred),\n",
    "    'Test_Recall': recall_score(y_test, y_test_pred),\n",
    "    'Test_F1': f1_score(y_test, y_test_pred)\n",
    "}\n",
    "\n",
    "predictions['gb'] = y_test_proba\n",
    "models_dict['gb'] = gb\n",
    "\n",
    "print(f\"  Val AUC: {results['Gradient Boosting']['Val_AUC']:.4f} | \"\n",
    "      f\"Test AUC: {results['Gradient Boosting']['Test_AUC']:.4f}\")\n",
    "\n",
    "print(\"\\n→ Training Neural Network...\")\n",
    "nn = MLPClassifier(\n",
    "    hidden_layer_sizes=(64, 32),\n",
    "    activation='relu',\n",
    "    solver='adam',\n",
    "    alpha=0.001,\n",
    "    learning_rate='adaptive',\n",
    "    max_iter=500,\n",
    "    early_stopping=True,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "nn.fit(X_train_balanced_scaled, y_train_balanced)\n",
    "\n",
    "y_val_proba = nn.predict_proba(X_val_scaled)[:, 1]\n",
    "y_test_pred = nn.predict(X_test_scaled)\n",
    "y_test_proba = nn.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "results['Neural Network'] = {\n",
    "    'Val_AUC': roc_auc_score(y_val, y_val_proba),\n",
    "    'Test_AUC': roc_auc_score(y_test, y_test_proba),\n",
    "    'Test_Accuracy': accuracy_score(y_test, y_test_pred),\n",
    "    'Test_Precision': precision_score(y_test, y_test_pred),\n",
    "    'Test_Recall': recall_score(y_test, y_test_pred),\n",
    "    'Test_F1': f1_score(y_test, y_test_pred)\n",
    "}\n",
    "\n",
    "predictions['nn'] = y_test_proba\n",
    "models_dict['nn'] = nn\n",
    "\n",
    "print(f\"  Val AUC: {results['Neural Network']['Val_AUC']:.4f} | \"\n",
    "      f\"Test AUC: {results['Neural Network']['Test_AUC']:.4f}\")\n",
    "\n",
    "for name, model in models_dict.items():\n",
    "    with open(f'output/models/{name}_model.pkl', 'wb') as f:\n",
    "        pickle.dump(model, f)\n",
    "\n",
    "print(\"\\n✅ Classical model training complete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f9aced08-432d-43bb-8e94-d214a3a952da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "STEP 5: QUANTUM MODEL SETUP\n",
      "============================================================\n",
      "\n",
      "Quantum Configuration:\n",
      "  Qubits        : 4\n",
      "  Layers        : 3\n",
      "  Backend       : AerSimulator\n",
      "  Shots         : 2048\n",
      "\n",
      "✅ Quantum circuit defined (Angle Encoding + Variational Ansatz + Parity Measurement)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 5: QUANTUM MODEL SETUP\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "from qiskit import QuantumCircuit\n",
    "from qiskit_aer import AerSimulator\n",
    "import numpy as np\n",
    "\n",
    "n_qubits = 4              \n",
    "NUM_LAYERS = 3           \n",
    "shots = 2048\n",
    "\n",
    "simulator = AerSimulator(method=\"statevector\")\n",
    "\n",
    "print(f\"\\nQuantum Configuration:\")\n",
    "print(f\"  Qubits        : {n_qubits}\")\n",
    "print(f\"  Layers        : {NUM_LAYERS}\")\n",
    "print(f\"  Backend       : AerSimulator\")\n",
    "print(f\"  Shots         : {shots}\")\n",
    "\n",
    "def feature_map(x):\n",
    "    qc = QuantumCircuit(n_qubits)\n",
    "    for i in range(n_qubits):\n",
    "        qc.ry(x[i], i)\n",
    "    return qc\n",
    "\n",
    "def variational_layer(params):\n",
    "    qc = QuantumCircuit(n_qubits)\n",
    "    p = params.reshape(NUM_LAYERS, n_qubits)\n",
    "\n",
    "    for layer in range(NUM_LAYERS):\n",
    "        for q in range(n_qubits):\n",
    "            qc.ry(p[layer, q], q)\n",
    "\n",
    "        for q in range(n_qubits):\n",
    "            qc.cx(q, (q + 1) % n_qubits)\n",
    "\n",
    "    return qc\n",
    "\n",
    "def quantum_model(x, params):\n",
    "    qc = QuantumCircuit(n_qubits)\n",
    "    qc.compose(feature_map(x), inplace=True)\n",
    "    qc.compose(variational_layer(params), inplace=True)\n",
    "    return qc\n",
    "\n",
    "def quantum_forward(x, params, shots=shots):\n",
    "    qc = quantum_model(x, params)\n",
    "    qc.measure_all()\n",
    "\n",
    "    result = simulator.run(qc, shots=shots).result()\n",
    "    counts = result.get_counts()\n",
    "\n",
    "    expectation = 0.0\n",
    "    for bitstring, count in counts.items():\n",
    "        parity = (-1) ** bitstring.count('1')\n",
    "        expectation += parity * count\n",
    "\n",
    "    return expectation / shots   # ∈ [-1, 1]\n",
    "\n",
    "def quantum_predict_proba(x, params, shots=shots):\n",
    "    exp_val = quantum_forward(x, params, shots)\n",
    "    return (exp_val + 1.0) / 2.0\n",
    "\n",
    "print(\"\\n Quantum circuit defined (Angle Encoding + Variational Ansatz + Parity Measurement)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "22d9140e-fdbd-4806-b5fe-c944fed2dd2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "STEP 6: QUANTUM TRAINING\n",
      "============================================================\n",
      "\n",
      "Training Configuration:\n",
      "  Training samples: 200\n",
      "  Positive: 97 | Negative: 103\n",
      "\n",
      "Starting training with COBYLA optimizer...\n",
      "============================================================\n",
      "Epoch  1/25 | Optimizing... | Time: 6.0s\n",
      "Epoch  2/25 | Optimizing... | Time: 4.9s\n",
      "Epoch  3/25 | Optimizing... | Time: 4.7s\n",
      "Epoch  4/25 | Optimizing... | Time: 4.6s\n",
      "Epoch  5/25 | Loss: 0.7344 | Time: 5.2s\n",
      "Epoch  6/25 | Optimizing... | Time: 5.1s\n",
      "Epoch  7/25 | Optimizing... | Time: 5.3s\n",
      "Epoch  8/25 | Optimizing... | Time: 5.4s\n",
      "Epoch  9/25 | Optimizing... | Time: 5.2s\n",
      "Epoch 10/25 | Loss: 0.6635 | Time: 4.8s\n",
      "Epoch 11/25 | Optimizing... | Time: 4.8s\n",
      "Epoch 12/25 | Optimizing... | Time: 4.6s\n",
      "Epoch 13/25 | Optimizing... | Time: 4.9s\n",
      "Epoch 14/25 | Optimizing... | Time: 5.3s\n",
      "Epoch 15/25 | Loss: 0.5665 | Time: 4.8s\n",
      "Epoch 16/25 | Optimizing... | Time: 4.8s\n",
      "Epoch 17/25 | Optimizing... | Time: 5.0s\n",
      "Epoch 18/25 | Optimizing... | Time: 4.9s\n",
      "Epoch 19/25 | Optimizing... | Time: 5.3s\n",
      "Epoch 20/25 | Loss: 0.5739 | Time: 4.9s\n",
      "Epoch 21/25 | Optimizing... | Time: 4.6s\n",
      "Epoch 22/25 | Optimizing... | Time: 4.6s\n",
      "Epoch 23/25 | Optimizing... | Time: 4.7s\n",
      "Epoch 24/25 | Optimizing... | Time: 5.2s\n",
      "Epoch 25/25 | Loss: 0.5661 | Time: 4.7s\n",
      "\n",
      "✅ Quantum training complete\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 6: QUANTUM TRAINING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from scipy.optimize import minimize\n",
    "import json\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "params = np.random.uniform(0, 2 * np.pi, size=n_qubits * NUM_LAYERS)\n",
    "\n",
    "train_size = min(200, len(X_train_quantum))  \n",
    "pos_idx = np.where(y_train == 1)[0]\n",
    "neg_idx = np.where(y_train == 0)[0]\n",
    "\n",
    "n_pos = min(train_size // 2, len(pos_idx))\n",
    "n_neg = min(train_size - n_pos, len(neg_idx))\n",
    "\n",
    "train_idx = np.concatenate([\n",
    "    np.random.choice(pos_idx, n_pos, replace=False),\n",
    "    np.random.choice(neg_idx, n_neg, replace=False)\n",
    "])\n",
    "\n",
    "X_train_qml = X_train_quantum[train_idx]\n",
    "y_train_qml = y_train.values[train_idx] if hasattr(y_train, 'values') else y_train[train_idx]\n",
    "\n",
    "print(f\"\\nTraining Configuration:\")\n",
    "print(f\"  Training samples: {len(X_train_qml)}\")\n",
    "print(f\"  Positive: {int(y_train_qml.sum())} | Negative: {len(y_train_qml) - int(y_train_qml.sum())}\")\n",
    "def binary_cross_entropy(y_true, y_pred):\n",
    "    eps = 1e-9\n",
    "    y_pred = np.clip(y_pred, eps, 1 - eps)\n",
    "    return -np.mean(\n",
    "        y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred)\n",
    "    )\n",
    "\n",
    "def compute_loss(params, X_subset, y_subset, shots=256):\n",
    "    preds = np.array([\n",
    "        quantum_predict_proba(x, params, shots) for x in X_subset\n",
    "    ])\n",
    "    return binary_cross_entropy(y_subset, preds)\n",
    "\n",
    "epochs = 25\n",
    "batch_size = min(50, len(X_train_qml))\n",
    "loss_history = []\n",
    "\n",
    "print(\"\\nStarting training with COBYLA optimizer...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    start_time = datetime.now()\n",
    "\n",
    "    batch_idx = np.random.choice(len(X_train_qml), batch_size, replace=False)\n",
    "    X_batch = X_train_qml[batch_idx]\n",
    "    y_batch = y_train_qml[batch_idx]\n",
    "\n",
    "    result = minimize(\n",
    "        compute_loss,\n",
    "        params,\n",
    "        args=(X_batch, y_batch, 512),\n",
    "        method='COBYLA',\n",
    "        options={\n",
    "            'maxiter': 40,\n",
    "            'rhobeg': 0.1\n",
    "        }\n",
    "    )\n",
    "\n",
    "    params = result.x\n",
    "\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        train_loss = compute_loss(\n",
    "            params,\n",
    "            X_train_qml[:50],\n",
    "            y_train_qml[:50],\n",
    "            shots=512\n",
    "        )\n",
    "        loss_history.append(train_loss)\n",
    "\n",
    "        elapsed = (datetime.now() - start_time).total_seconds()\n",
    "        print(f\"Epoch {epoch+1:2d}/{epochs} | Loss: {train_loss:.4f} | Time: {elapsed:.1f}s\")\n",
    "    else:\n",
    "        elapsed = (datetime.now() - start_time).total_seconds()\n",
    "        print(f\"Epoch {epoch+1:2d}/{epochs} | Optimizing... | Time: {elapsed:.1f}s\")\n",
    "\n",
    "quantum_model_data = {\n",
    "    'params': params.tolist(),\n",
    "    'n_qubits': n_qubits,\n",
    "    'num_layers': NUM_LAYERS,\n",
    "    'loss_history': loss_history\n",
    "}\n",
    "\n",
    "with open('output/models/quantum_model.json', 'w') as f:\n",
    "    json.dump(quantum_model_data, f, indent=2)\n",
    "\n",
    "print(\"\\n Quantum training complete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "75abfbf7-2c52-47b7-8ef0-5f6109df223a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "STEP 7: QUANTUM EVALUATION\n",
      "============================================================\n",
      "\n",
      "Evaluating Quantum Model on Test Set...\n",
      "  Processed 100/135 samples\n",
      "\n",
      "Quantum Model Performance:\n",
      "  Test AUC:       0.7235\n",
      "  Test Accuracy:  0.5333\n",
      "  Test Precision: 0.4352\n",
      "  Test Recall:    0.9592\n",
      "  Test F1-score:  0.5987\n",
      "\n",
      "✅ Quantum evaluation complete\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 7: QUANTUM EVALUATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nEvaluating Quantum Model on Test Set...\")\n",
    "\n",
    "y_test_proba_quantum = []\n",
    "\n",
    "for i, x in enumerate(X_test_quantum):\n",
    "    if i % 100 == 0:\n",
    "        print(f\"  Processed {i}/{len(X_test_quantum)} samples\", end='\\r')\n",
    "\n",
    "    p = quantum_predict_proba(x, params, shots=2048)\n",
    "    y_test_proba_quantum.append(p)\n",
    "\n",
    "print() \n",
    "y_test_proba_quantum = np.array(y_test_proba_quantum)\n",
    "\n",
    "y_test_pred_quantum = (y_test_proba_quantum >= 0.5).astype(int)\n",
    "\n",
    "results['Quantum VQC'] = {\n",
    "    'Test_AUC': roc_auc_score(y_test, y_test_proba_quantum),\n",
    "    'Test_Accuracy': accuracy_score(y_test, y_test_pred_quantum),\n",
    "    'Test_Precision': precision_score(y_test, y_test_pred_quantum, zero_division=0),\n",
    "    'Test_Recall': recall_score(y_test, y_test_pred_quantum, zero_division=0),\n",
    "    'Test_F1': f1_score(y_test, y_test_pred_quantum, zero_division=0)\n",
    "}\n",
    "\n",
    "predictions['quantum'] = y_test_proba_quantum\n",
    "\n",
    "print(\"\\nQuantum Model Performance:\")\n",
    "print(f\"  Test AUC:       {results['Quantum VQC']['Test_AUC']:.4f}\")\n",
    "print(f\"  Test Accuracy:  {results['Quantum VQC']['Test_Accuracy']:.4f}\")\n",
    "print(f\"  Test Precision: {results['Quantum VQC']['Test_Precision']:.4f}\")\n",
    "print(f\"  Test Recall:    {results['Quantum VQC']['Test_Recall']:.4f}\")\n",
    "print(f\"  Test F1-score:  {results['Quantum VQC']['Test_F1']:.4f}\")\n",
    "\n",
    "print(\"\\n Quantum evaluation complete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e328677f-42b0-4eff-bc5c-2b1fbcd1a927",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
